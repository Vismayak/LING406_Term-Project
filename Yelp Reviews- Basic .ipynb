{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - Basic Baseline System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to take the same baseline system developed previously and use it on Yelp Reviews to seperate the good reviews (or those that are 3.5 stars and above) and the bad reviews (less than 3.5 stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the various python libraries that would be needed in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"yelp_reviews/all_reviews.txt\"\n",
    "\n",
    "with open(filename) as file:\n",
    "    text = file.read()\n",
    "\n",
    "reviews = text.split(\"]]]\")\n",
    "del reviews[10391] #removing a particular garbage value\n",
    "reviews[0] = '\\n'+reviews[0] # adding hashtag to keep consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate each review to return star rating and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_review(review):\n",
    "    stars =  review[5] \n",
    "    text = review[21:]\n",
    "    return int(stars),text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning text and updating the Vocabulary (The vocabulary needs to be constantly updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_vocab(tokens,vocab):    \n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the vocabulary as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_vocab(vocab):\n",
    "    voc = [i for i,j in vocab.items()]\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting reviews into training and testing lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_review = reviews[:8500]\n",
    "testing_review = reviews[8500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary using the previous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A counter that would be used for vocabulary\n",
    "pos_vocab = Counter() # initialize the counter to be used throughout\n",
    "neg_vocab = Counter()\n",
    "\n",
    "for i in training_review:\n",
    "    stars,text = evaluate_review(i)\n",
    "    tokens = text.split()\n",
    "    if stars > 3:\n",
    "        update_vocab(tokens,pos_vocab)\n",
    "    elif stars < 3:\n",
    "        update_vocab(tokens,neg_vocab)\n",
    "    elif stars == 3:\n",
    "        if ('3.5' in tokens) and ('stars' in tokens):\n",
    "            update_vocab(tokens,pos_vocab)\n",
    "        else:\n",
    "            update_vocab(tokens,neg_vocab)\n",
    "\n",
    "pos_vocabulary= save_vocab(pos_vocab) \n",
    "neg_vocabulary = save_vocab(neg_vocab)\n",
    "#print(pos_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_review():\n",
    "    correct = 0\n",
    "    for i in testing_review:\n",
    "        stars,text = evaluate_review(i)\n",
    "        tokens = clean_text(i)\n",
    "        pos_decision =0\n",
    "        neg_decision = 0\n",
    "        for i in tokens:\n",
    "            if i in pos_vocabulary:\n",
    "                pos_decision += 1 #* pos_vocab[i]/pos_sum   # weights were taken off cos of reason stated above\n",
    "            if i in neg_vocabulary:\n",
    "                neg_decision +=1 #* neg_vocab[i]/neg_sum\n",
    "        if pos_decision >= neg_decision :\n",
    "            pos = 1\n",
    "        else:\n",
    "            pos = -1\n",
    "        if stars > 3:\n",
    "            if pos == 1:\n",
    "                correct += 1\n",
    "        elif stars < 3:\n",
    "            if pos == -1:\n",
    "                correct += 1\n",
    "        elif stars == 3:\n",
    "            if ('3.5' in tokens) and ('stars' in tokens):\n",
    "                if pos == 1:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                if pos == -1:\n",
    "                    correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 69.32839767318879\n"
     ]
    }
   ],
   "source": [
    "number_of_corrects = test_review() #we are testing on the positive files\n",
    "accuracy =  number_of_corrects/len(testing_review) * 100\n",
    "\n",
    "print (\"Accuracy is \"+ str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
